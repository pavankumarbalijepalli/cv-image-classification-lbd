{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809cfe4d-75da-42d6-a2fc-c832c0ba5062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8c0360-0c48-4492-aaf2-3a0b14fdd358",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading metadata: 100%|██████████| 1.12k/1.12k [00:00<00:00, 739kB/s]\n",
      "Downloading readme: 100%|██████████| 4.37k/4.37k [00:00<00:00, 2.86MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None (download: 271.88 MiB, generated: 309.93 MiB, post-processed: Unknown size, total: 581.81 MiB) to /home/codespace/.cache/huggingface/datasets/sasha___parquet/sasha--dog-food-ec42a61d5519cc88/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/199M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   5%|▌         | 10.0M/199M [00:00<00:01, 100MB/s]\u001b[A\n",
      "Downloading data:  10%|█         | 20.0M/199M [00:00<00:01, 97.1MB/s]\u001b[A\n",
      "Downloading data:  15%|█▍        | 29.7M/199M [00:00<00:01, 94.6MB/s]\u001b[A\n",
      "Downloading data:  20%|█▉        | 39.2M/199M [00:00<00:01, 94.5MB/s]\u001b[A\n",
      "Downloading data:  24%|██▍       | 48.6M/199M [00:00<00:01, 91.1MB/s]\u001b[A\n",
      "Downloading data:  29%|██▉       | 57.8M/199M [00:00<00:01, 82.6MB/s]\u001b[A\n",
      "Downloading data:  33%|███▎      | 66.2M/199M [00:00<00:01, 80.1MB/s]\u001b[A\n",
      "Downloading data:  38%|███▊      | 76.5M/199M [00:00<00:01, 87.0MB/s]\u001b[A\n",
      "Downloading data:  43%|████▎     | 85.5M/199M [00:00<00:01, 87.8MB/s]\u001b[A\n",
      "Downloading data:  48%|████▊     | 96.1M/199M [00:01<00:01, 93.2MB/s]\u001b[A\n",
      "Downloading data:  53%|█████▎    | 106M/199M [00:01<00:01, 65.7MB/s] \u001b[A\n",
      "Downloading data:  58%|█████▊    | 115M/199M [00:01<00:01, 72.0MB/s]\u001b[A\n",
      "Downloading data:  62%|██████▏   | 124M/199M [00:01<00:00, 77.4MB/s]\u001b[A\n",
      "Downloading data:  67%|██████▋   | 133M/199M [00:01<00:00, 69.8MB/s]\u001b[A\n",
      "Downloading data:  71%|███████▏  | 142M/199M [00:01<00:00, 75.4MB/s]\u001b[A\n",
      "Downloading data:  76%|███████▌  | 151M/199M [00:01<00:00, 80.0MB/s]\u001b[A\n",
      "Downloading data:  81%|████████  | 161M/199M [00:01<00:00, 83.3MB/s]\u001b[A\n",
      "Downloading data:  85%|████████▌ | 170M/199M [00:02<00:00, 86.1MB/s]\u001b[A\n",
      "Downloading data:  90%|████████▉ | 179M/199M [00:02<00:00, 88.0MB/s]\u001b[A\n",
      "Downloading data:  95%|█████████▍| 189M/199M [00:02<00:00, 89.5MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 199M/199M [00:02<00:00, 83.7MB/s]\u001b[A\n",
      "Downloading data files:  50%|█████     | 1/2 [00:03<00:03,  3.93s/it]\n",
      "Downloading data:   0%|          | 0.00/85.8M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   0%|          | 17.4k/85.8M [00:00<16:51, 84.8kB/s]\u001b[A\n",
      "Downloading data:   0%|          | 50.2k/85.8M [00:00<11:13, 127kB/s] \u001b[A\n",
      "Downloading data:   0%|          | 137k/85.8M [00:00<05:30, 259kB/s] \u001b[A\n",
      "Downloading data:   0%|          | 311k/85.8M [00:00<02:56, 484kB/s]\u001b[A\n",
      "Downloading data:   1%|          | 659k/85.8M [00:01<01:33, 910kB/s]\u001b[A\n",
      "Downloading data:   2%|▏         | 1.34M/85.8M [00:01<00:49, 1.70MB/s]\u001b[A\n",
      "Downloading data:   3%|▎         | 2.71M/85.8M [00:01<00:25, 3.28MB/s]\u001b[A\n",
      "Downloading data:   6%|▋         | 5.46M/85.8M [00:01<00:12, 6.42MB/s]\u001b[A\n",
      "Downloading data:  11%|█         | 9.38M/85.8M [00:01<00:07, 10.2MB/s]\u001b[A\n",
      "Downloading data:  16%|█▌        | 13.4M/85.8M [00:02<00:05, 12.8MB/s]\u001b[A\n",
      "Downloading data:  20%|█▉        | 16.8M/85.8M [00:02<00:05, 13.5MB/s]\u001b[A\n",
      "Downloading data:  21%|██        | 18.1M/85.8M [00:02<00:05, 11.3MB/s]\u001b[A\n",
      "Downloading data:  25%|██▍       | 21.1M/85.8M [00:02<00:05, 12.4MB/s]\u001b[A\n",
      "Downloading data:  26%|██▋       | 22.5M/85.8M [00:02<00:05, 10.6MB/s]\u001b[A\n",
      "Downloading data:  27%|██▋       | 23.6M/85.8M [00:03<00:05, 10.4MB/s]\u001b[A\n",
      "Downloading data:  31%|███       | 26.3M/85.8M [00:03<00:05, 11.4MB/s]\u001b[A\n",
      "Downloading data:  34%|███▎      | 28.9M/85.8M [00:03<00:04, 11.5MB/s]\u001b[A\n",
      "Downloading data:  35%|███▍      | 30.0M/85.8M [00:03<00:04, 11.4MB/s]\u001b[A\n",
      "Downloading data:  37%|███▋      | 32.1M/85.8M [00:03<00:04, 13.3MB/s]\u001b[A\n",
      "Downloading data:  39%|███▉      | 33.5M/85.8M [00:03<00:03, 13.5MB/s]\u001b[A\n",
      "Downloading data:  41%|████      | 35.0M/85.8M [00:03<00:03, 13.4MB/s]\u001b[A\n",
      "Downloading data:  42%|████▏     | 36.4M/85.8M [00:04<00:03, 13.5MB/s]\u001b[A\n",
      "Downloading data:  44%|████▍     | 37.9M/85.8M [00:04<00:03, 13.6MB/s]\u001b[A\n",
      "Downloading data:  46%|████▌     | 39.3M/85.8M [00:04<00:03, 13.5MB/s]\u001b[A\n",
      "Downloading data:  48%|████▊     | 40.8M/85.8M [00:04<00:03, 13.9MB/s]\u001b[A\n",
      "Downloading data:  49%|████▉     | 42.3M/85.8M [00:04<00:03, 13.7MB/s]\u001b[A\n",
      "Downloading data:  51%|█████     | 43.8M/85.8M [00:04<00:02, 14.1MB/s]\u001b[A\n",
      "Downloading data:  53%|█████▎    | 45.2M/85.8M [00:04<00:02, 13.9MB/s]\u001b[A\n",
      "Downloading data:  55%|█████▍    | 46.8M/85.8M [00:04<00:02, 14.3MB/s]\u001b[A\n",
      "Downloading data:  56%|█████▌    | 48.3M/85.8M [00:04<00:02, 14.0MB/s]\u001b[A\n",
      "Downloading data:  58%|█████▊    | 49.8M/85.8M [00:04<00:02, 14.4MB/s]\u001b[A\n",
      "Downloading data:  60%|█████▉    | 51.3M/85.8M [00:05<00:02, 14.1MB/s]\u001b[A\n",
      "Downloading data:  62%|██████▏   | 52.9M/85.8M [00:05<00:02, 14.7MB/s]\u001b[A\n",
      "Downloading data:  63%|██████▎   | 54.4M/85.8M [00:05<00:02, 14.3MB/s]\u001b[A\n",
      "Downloading data:  65%|██████▌   | 55.8M/85.8M [00:05<00:02, 14.1MB/s]\u001b[A\n",
      "Downloading data:  67%|██████▋   | 57.2M/85.8M [00:05<00:02, 14.0MB/s]\u001b[A\n",
      "Downloading data:  68%|██████▊   | 58.7M/85.8M [00:05<00:01, 13.9MB/s]\u001b[A\n",
      "Downloading data:  70%|██████▉   | 60.0M/85.8M [00:05<00:01, 13.6MB/s]\u001b[A\n",
      "Downloading data:  72%|███████▏  | 61.8M/85.8M [00:05<00:01, 14.6MB/s]\u001b[A\n",
      "Downloading data:  74%|███████▎  | 63.3M/85.8M [00:05<00:01, 14.1MB/s]\u001b[A\n",
      "Downloading data:  75%|███████▌  | 64.8M/85.8M [00:06<00:01, 14.4MB/s]\u001b[A\n",
      "Downloading data:  77%|███████▋  | 66.2M/85.8M [00:06<00:01, 14.1MB/s]\u001b[A\n",
      "Downloading data:  79%|███████▉  | 67.9M/85.8M [00:06<00:01, 14.7MB/s]\u001b[A\n",
      "Downloading data:  81%|████████  | 69.3M/85.8M [00:06<00:01, 14.2MB/s]\u001b[A\n",
      "Downloading data:  83%|████████▎ | 71.2M/85.8M [00:06<00:00, 15.4MB/s]\u001b[A\n",
      "Downloading data:  85%|████████▍ | 72.7M/85.8M [00:06<00:00, 14.9MB/s]\u001b[A\n",
      "Downloading data:  87%|████████▋ | 74.6M/85.8M [00:06<00:00, 16.0MB/s]\u001b[A\n",
      "Downloading data:  89%|████████▉ | 76.2M/85.8M [00:06<00:00, 15.4MB/s]\u001b[A\n",
      "Downloading data:  91%|█████████ | 78.2M/85.8M [00:06<00:00, 13.0MB/s]\u001b[A\n",
      "Downloading data:  93%|█████████▎| 80.1M/85.8M [00:07<00:00, 14.4MB/s]\u001b[A\n",
      "Downloading data:  95%|█████████▌| 81.7M/85.8M [00:07<00:00, 14.3MB/s]\u001b[A\n",
      "Downloading data:  97%|█████████▋| 83.6M/85.8M [00:07<00:00, 15.5MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 85.8M/85.8M [00:07<00:00, 11.6MB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████| 2/2 [00:13<00:00,  6.59s/it]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 925.18it/s]\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/codespace/.cache/huggingface/datasets/sasha___parquet/sasha--dog-food-ec42a61d5519cc88/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 39.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sasha/dog-food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59929ac9-7469-46de-a5e7-d95bc801d021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dog': '0', 'food': '1'}, {'0': 'dog', '1': 'food'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "    \n",
    "label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a0098c-cbe1-4a4c-8e43-6d81a4534a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)rocessor_config.json: 100%|██████████| 160/160 [00:00<00:00, 149kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 502/502 [00:00<00:00, 398kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f07b7ed-c2a9-422d-b720-2ef5c4327825",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:36:18.452006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-12 14:36:19.470337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "\n",
    "train_data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomCrop(size[0], size[1]),\n",
    "        layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ],\n",
    "    name=\"train_data_augmentation\",\n",
    ")\n",
    "\n",
    "val_data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.CenterCrop(size[0], size[1]),\n",
    "        layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "    ],\n",
    "    name=\"val_data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c4fa58-6cf3-4a0b-b016-16723dc5ecb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_to_tf_tensor(image: Image):\n",
    "    np_image = np.array(image)\n",
    "    tf_image = tf.convert_to_tensor(np_image)\n",
    "    # `expand_dims()` is used to add a batch dimension since\n",
    "    # the TF augmentation layers operates on batched inputs.\n",
    "    return tf.expand_dims(tf_image, 0)\n",
    "\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    images = [\n",
    "        train_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n",
    "    return example_batch\n",
    "\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    images = [\n",
    "        val_data_augmentation(convert_to_tf_tensor(image.convert(\"RGB\"))) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    example_batch[\"pixel_values\"] = [tf.transpose(tf.squeeze(image)) for image in images]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0193a062-60d0-48ca-bf79-cf146cd2c1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"].set_transform(preprocess_train)\n",
    "dataset[\"test\"].set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70c8dcea-39c9-4395-8ceb-1b84a938a28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04e00f8a-3a53-4c84-b988-31c147c8cbde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 2.37MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ba4222e-5f17-414d-bfe8-f922dd72f354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f893748-80d7-4561-945b-34fd6ea622c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\ncreate_optimizer requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3e-5\u001b[39m\n\u001b[1;32m      7\u001b[0m weight_decay_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m----> 9\u001b[0m optimizer, lr_schedule \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_optimizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_warmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/transformers/utils/dummy_tf_objects.py:2802\u001b[0m, in \u001b[0;36mcreate_optimizer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_optimizer\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2802\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/transformers/utils/import_utils.py:1049\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(TF_IMPORT_ERROR_WITH_PYTORCH\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   1051\u001b[0m checks \u001b[38;5;241m=\u001b[39m (BACKENDS_MAPPING[backend] \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends)\n\u001b[1;32m   1052\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n",
      "\u001b[0;31mImportError\u001b[0m: \ncreate_optimizer requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "num_train_steps = len(dataset[\"train\"]) * num_epochs\n",
    "learning_rate = 3e-5\n",
    "weight_decay_rate = 0.01\n",
    "\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "231acba9-2a0d-4e23-bd3c-ee06335abf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nTFAutoModelForImageClassification requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFAutoModelForImageClassification\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModelForImageClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\n\u001b[1;32m      4\u001b[0m     checkpoint,\n\u001b[1;32m      5\u001b[0m     id2label\u001b[38;5;241m=\u001b[39mid2label,\n\u001b[1;32m      6\u001b[0m     label2id\u001b[38;5;241m=\u001b[39mlabel2id,\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/transformers/utils/import_utils.py:1066\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1066\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/transformers/utils/import_utils.py:1049\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(TF_IMPORT_ERROR_WITH_PYTORCH\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   1051\u001b[0m checks \u001b[38;5;241m=\u001b[39m (BACKENDS_MAPPING[backend] \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends)\n\u001b[1;32m   1052\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n",
      "\u001b[0;31mImportError\u001b[0m: \nTFAutoModelForImageClassification requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForImageClassification\n",
    "\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501daed-00ee-4570-abf7-9e3998b8aaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
